
以下基于 centos 8 


1. 二进制安装

127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4
::1         localhost localhost.localdomain localhost6 localhost6.localdomain6
10.10.10.70   k8s-master01
10.10.10.72   k8s-master02
10.10.10.81   k8s-master03
10.10.10.236  k8s-master-lb #vip 虚拟ip不占用机器资源，如果不是高可用集群，该ip为master01的ip
10.10.10.82   k8s-node01
10.10.10.74   k8s-node02
    
k8s service网段: 10.96.0.0/12
k8s pod网段: 172.168.0.0/12

宿主机, service, pod网段 三个不能重复

1.1 配置所有节点host文件，用上面的

1.2 配置yum源，配置阿里云的yum源会比较快
    cd /etc/yum.repos.d/
    sed -i 's/mirrorlist/#mirrorlist/g' /etc/yum.repos.d/CentOS-*
    sed -i 's|#baseurl=http://mirror.centos.org|baseurl=http://vault.centos.org|g' /etc/yum.repos.d/CentOS-*

    wget -O /etc/yum.repos.d/CentOS-Base.repo https://mirrors.aliyun.com/repo/Centos-vault-8.5.2111.repo

    yum clean all && yum makecache


    第二种：更新yum源
        rm -rf /etc/yum.repos.d/*  ; wget ftp://ftp.rhce.cc/k8s/* -P /etc/yum.repos.d/
        yum clean all




1.3 所有节点必备工具安装
yum install -y wget jq psmisc vim net-tools telnet yum-utils device-mapper-persistent-data lvm2 git
yum -y install socat conntrack iproute-tc


1.4 所有节点关闭防火墙等
systemctl disable --now firewalld  
systemctl disable --now dnsmasq
systemctl disable --now NetworkManager (Centos7需要关闭，centos8不需要)

setenforce 0
sed -i 's#SELINUX=enforcing#SELINUX=disabled#g' /etc/sysconfig/selinux
sed -i 's#SELINUX=enforcing#SELINUX=disabled#g' /etc/selinux/config

systemctl disable --now firewalld && systemctl disable --now dnsmasq 
setenforce 0 && sed -i 's#SELINUX=enforcing#SELINUX=disabled#g' /etc/sysconfig/selinux && sed -i 's#SELINUX=enforcing#SELINUX=disabled#g' /etc/selinux/config

1.5 所有节点关闭swap分区，fstab注释swap
swapoff -a && sysctl -w vm.swappiness=0
sed -ri '/^[^#]*swap/s@^@#@' /etc/fstab

swapoff -a && sysctl -w vm.swappiness=0 && sed -ri '/^[^#]*swap/s@^@#@' /etc/fstab



# 将桥接的 IPV4 流量传递到 iptables 的链
Verify that the br_netfilter module is loaded by running:
     lsmod | grep br_netfilter

cat <<EOF | sudo tee /etc/modules-load.d/k8s.conf
overlay
br_netfilter
EOF

sudo modprobe overlay
sudo modprobe br_netfilter

# sysctl params required by setup, params persist across reboots
cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-iptables  = 1
net.bridge.bridge-nf-call-ip6tables = 1
net.ipv4.ip_forward                 = 1
EOF

# Apply sysctl params without reboot
sudo sysctl --system



1.6 所有节点同步时间
    安装 ntpdate
    rpm -ivh http://mirrors.wlnmp.com/centos/wlnmp-release-centos.noarch.rpm
    dnf  install wntp -y
    
    ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime
    echo 'Asia/Shanghai' > /etc/timezone

    ntpdate ntp3.aliyun.com 
    加入到crontab中, crontab -e
    */5 * * * * ntpdate ntp3.aliyun.com

    一键：
        rpm -ivh http://mirrors.wlnmp.com/centos/wlnmp-release-centos.noarch.rpm && dnf  install wntp -y && ln -sf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime && echo 'Asia/Shanghai' > /etc/timezone && ntpdate ntp3.aliyun.com
    手动加入crontab

1.7 所有节点配置limit

ulimit -SHn 65535
    
vim /etc/security/limits.conf

* soft nofile 655360
* hard nofile 131072
* soft nproc 655350
* hard nproc 655350
* soft memlock unlimited
* hard memlock unlimited


1.8 Master01生成密钥，免登录其他节点，用来发文件配置等
ssh-keygen -t rsa

for i in k8s-master01 k8s-master02 k8s-master03 k8s-node01 k8s-node02;do ssh-copy-id -i ~/.ssh/id_rsa.pub $i;done





1. 使用kubeadm安装
    1.1 如果使用docker，确实docker的cgroup driver使用 systemd，kubelet也要用 systemd，保持一致。可以参考docker.txt的内容

    使用docker的话，需要用到 cri-dockerd
        参考：https://github.com/Mirantis/cri-dockerd


所有节点上安装 kubeadm, kubelet, kubectl


#vim  /etc/systemd/system/kubelet.service

[Unit]
Description=kubelet: The Kubernetes Node Agent
Documentation=https://kubernetes.io/docs/home/
Wants=network-online.target
After=network-online.target

[Service]
ExecStart=/usr/local/bin/kubelet  
#ExecStart=/usr/local/bin/kubelet --container-runtime=remote --container-runtime-endpoint=unix:///var/run/cri-dockerd.sock
Restart=always
StartLimitInterval=0
RestartSec=10

[Install]
WantedBy=multi-user.target


# mkdir -p /etc/systemd/system/kubelet.service.d
#vim /etc/systemd/system/kubelet.service.d/10-kubeadm.conf

# Note: This dropin only works with kubeadm and kubelet v1.11+
[Service]
Environment="KUBELET_KUBECONFIG_ARGS=--bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf"
Environment="KUBELET_CONFIG_ARGS=--config=/var/lib/kubelet/config.yaml"

# This is a file that "kubeadm init" and "kubeadm join" generates at runtime, populating the KUBELET_KUBEADM_ARGS variable dynamically
EnvironmentFile=-/var/lib/kubelet/kubeadm-flags.env
# This is a file that the user can use for overrides of the kubelet args as a last resort. Preferably, the user should use
# the .NodeRegistration.KubeletExtraArgs object in the configuration files instead. KUBELET_EXTRA_ARGS should be sourced from this file.
EnvironmentFile=-/etc/default/kubelet
ExecStart=
ExecStart=/usr/local/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS



# vim /var/lib/kubelet/kubeadm-flags.env
[root@VM-4-3-centos net.d]# cat /var/lib/kubelet/kubeadm-flags.env
KUBELET_KUBEADM_ARGS="--container-runtime=remote --container-runtime-endpoint=unix:///var/run/cri-dockerd.sock --pod-infra-container-image=k8s.gcr.io/pause:3.7"
修改  k8s.gcr.io/pause:3.7 为 registry.aliyuncs.com/google_containers/pause:3.7
这里改了以后
KUBELET_KUBEADM_ARGS="--container-runtime=remote --container-runtime-endpoint=unix:///var/run/cri-dockerd.sock --pod-infra-container-image=registry.aliyuncs.com/google_containers/pause:3.7"



systemctl enable kubelet




配置cgroup driver ：v1.22不配置，默认systemd，所以下面的不需要了

    Configuring a cgroup driver 
    Both the container runtime and the kubelet have a property called "cgroup driver", which is important for the management of cgroups on Linux machines.

    Note: In v1.22, if the user is not setting the cgroupDriver field under KubeletConfiguration, kubeadm will default it to systemd.
    v1.22不配置，默认systemd，所以下面的不需要了

    给k8s配置cgroup driver：
        要求container runtime和kubeadmin要用的一样的

    在 kubeadm init上面指定配置文件，写到配置文件中
    # kubeadm-config.yaml
    kind: ClusterConfiguration
    apiVersion: kubeadm.k8s.io/v1beta3
    kubernetesVersion: v1.21.0
    ---
    kind: KubeletConfiguration
    apiVersion: kubelet.config.k8s.io/v1beta1
    cgroupDriver: systemd

    kubeadm init --config kubeadm-config.yaml


可以查看都需要拉哪些镜像：
    可以本地连接vpn下载下来，docker save成压缩包，上传到服务器上，docker load出来
    也可以vpn下载下来，tag成自己的阿里云镜像地址，上传到阿里云镜像仓库，然后服务器pull下来，再打成对应的tag，没有第一个方便
   
    # kubeadm config images list

    I0827 18:57:50.857823   74211 version.go:255] remote version is much newer: v1.25.0; falling back to: stable-1.24
    k8s.gcr.io/kube-apiserver:v1.24.4
    k8s.gcr.io/kube-controller-manager:v1.24.4
    k8s.gcr.io/kube-scheduler:v1.24.4
    k8s.gcr.io/kube-proxy:v1.24.4
    k8s.gcr.io/pause:3.7
    k8s.gcr.io/etcd:3.5.3-0
    k8s.gcr.io/coredns/coredns:v1.8.6

kubeadm init --cri-socket='unix:///var/run/cri-dockerd.sock'


#####配置 kubectl
    mkdir -p $HOME/.kube
    sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
    sudo chown $(id -u):$(id -g) $HOME/.kube/config





排错：
    1. kubelet配置文件
    cat /var/lib/kubelet/config.yaml |grep group


    2、 [root@VM-4-3-centos ~]# cat /etc/kubernetes/manifests/
    etcd.yaml                     kube-apiserver.yaml           kube-controller-manager.yaml  kube-scheduler.yaml

    3. tc not found in system path
        yum -y install iproute-tc

    4. 清理node
        kubeadm reset 
        kubectl delete node nodeName
        rm -rf /etc/cni/net.d
        iptables -F
        kubeadm reset